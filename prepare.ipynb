{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise \n",
    "Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Paul Erdős and George Pólya are influential Hungarian mathematicians who contributed a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = \"Paul Erdős and George Pólya are influential Hungarian mathematicians who contributed a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\"\n",
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdős and george pólya are influential hungarian mathematicians who contributed a lot to the field. erdős's name contains the hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as erdos or erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lowercase everything\n",
    "string = original.lower()\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field. erdos's name contains the hungarian letter 'o' ('o' with double acute accent), but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalize unicode characters\n",
    "string = original.lower()\n",
    "string = unicodedata.normalize('NFKD', string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')    \n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field erdos's name contains the hungarian letter 'o' 'o' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "string = re.sub(r\"[^a-z0-9\\s']\", '', string)\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string:str):\n",
    "    #Lowercase everything\n",
    "    string = string.lower()\n",
    "    #Normalize unicode characters\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "    #Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "    string = re.sub(r\"[^a-z0-9\\s']\", '', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise \n",
    "Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field erdos's name contains the hungarian letter 'o' 'o' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = basic_clean(original)\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(clean_string:str):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    string = tokenizer.tokenize(clean_string, return_str=True)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text= tokenize(clean_text)\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise \n",
    "Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise \n",
    "Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdos',\n",
       " 'and',\n",
       " 'george',\n",
       " 'polya',\n",
       " 'are',\n",
       " 'influential',\n",
       " 'hungarian',\n",
       " 'mathematician',\n",
       " 'who',\n",
       " 'contributed',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'to',\n",
       " 'the',\n",
       " 'field',\n",
       " 'erdos',\n",
       " \"'\",\n",
       " 's',\n",
       " 'name',\n",
       " 'contains',\n",
       " 'the',\n",
       " 'hungarian',\n",
       " 'letter',\n",
       " \"'\",\n",
       " 'o',\n",
       " \"'\",\n",
       " \"'\",\n",
       " 'o',\n",
       " \"'\",\n",
       " 'with',\n",
       " 'double',\n",
       " 'acute',\n",
       " 'accent',\n",
       " 'but',\n",
       " 'is',\n",
       " 'often',\n",
       " 'incorrectly',\n",
       " 'written',\n",
       " 'a',\n",
       " 'erdos',\n",
       " 'or',\n",
       " 'erdos',\n",
       " 'either',\n",
       " 'by',\n",
       " 'mistake',\n",
       " 'or',\n",
       " 'out',\n",
       " 'of',\n",
       " 'typographical',\n",
       " 'necessity']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = [wnl.lemmatize(word) for word in tokenized_text.split()]\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tokenized_string:str):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in tokenized_string.split()]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdos',\n",
       " 'and',\n",
       " 'george',\n",
       " 'polya',\n",
       " 'are',\n",
       " 'influential',\n",
       " 'hungarian',\n",
       " 'mathematician',\n",
       " 'who',\n",
       " 'contributed',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'to',\n",
       " 'the',\n",
       " 'field',\n",
       " 'erdos',\n",
       " \"'\",\n",
       " 's',\n",
       " 'name',\n",
       " 'contains',\n",
       " 'the',\n",
       " 'hungarian',\n",
       " 'letter',\n",
       " \"'\",\n",
       " 'o',\n",
       " \"'\",\n",
       " \"'\",\n",
       " 'o',\n",
       " \"'\",\n",
       " 'with',\n",
       " 'double',\n",
       " 'acute',\n",
       " 'accent',\n",
       " 'but',\n",
       " 'is',\n",
       " 'often',\n",
       " 'incorrectly',\n",
       " 'written',\n",
       " 'a',\n",
       " 'erdos',\n",
       " 'or',\n",
       " 'erdos',\n",
       " 'either',\n",
       " 'by',\n",
       " 'mistake',\n",
       " 'or',\n",
       " 'out',\n",
       " 'of',\n",
       " 'typographical',\n",
       " 'necessity']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_text=lemmatize(tokenized_text)\n",
    "lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise \n",
    "Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yipengjiang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "stopword_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_removed_text = [word for word in lemmatized_text if word not in stopword_list]\n",
    "len(stopword_removed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos george polya influential hungarian mathematician contributed lot field erdos ' name contains hungarian letter ' ' ' ' double acute accent often incorrectly written erdos erdos either mistake typographical necessity\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(stopword_removed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(lemmatized_string):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    stopword_removed_string =  [word for word in lemmatized_text if word not in stopword_list]\n",
    "    return ' '.join(stopword_removed_string)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos george polya influential hungarian mathematician contributed lot field erdos ' name contains hungarian letter ' ' ' ' double acute accent often incorrectly written erdos erdos either mistake typographical necessity\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_removed_text = remove_stopwords(lemmatized_text)\n",
    "stopword_removed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise \n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise \n",
    "Define a function named prep_article that takes in the dictionary representing an article and returns a dictionary that looks like this:\n",
    "\n",
    "{\n",
    "    'title': 'the original title'.\n",
    "    'original': original,\n",
    "    'stemmed': article_stemmed,\n",
    "    'lemmatized': article_lemmatized,\n",
    "    'clean': article_without_stopwords\n",
    "}\n",
    "Note that if the orignal dictionary has a title property, it should remain unchanged (same goes for the category property)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise \n",
    "Define a function named prepare_article_data that takes in the list of articles dictionaries, applies the prep_article function to each one, and returns the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(original:str):\n",
    "    clean_text = basic_clean(original)\n",
    "    tokenized_text= tokenize(clean_text)\n",
    "    lemmatized_text=lemmatize(tokenized_text)\n",
    "    prepared_text = remove_stopwords(lemmatized_text)\n",
    "    return prepared_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos george polya influential hungarian mathematician contributed lot field erdos ' name contains hungarian letter ' ' ' ' double acute accent often incorrectly written erdos erdos either mistake typographical necessity\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_text(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
